{
 "metadata": {
  "name": "",
  "signature": "sha256:8f2d486fdca569849a6b04425de87c9360f64e127a28b406e74d3d33311f3520"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "18-889e: Home work 1 Solution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note for Venkat: If you can open this, you have successfully managed to install ipython and the ipython notebook. Basically this forms a neat way for me to view the progress of my ideas so I tend to use it for homeworks. We can switch to scripts if you prefer that instead as well. Also, I've imported the 'numpy' package into python. The syntax of using that is close to Matlab so I thought it would make things more comfortable for you. \n",
      "The whole program is divided into cells that must be run in the order they appear. Basically you have to keep hitting 'Shift+Enter' to run the whole program. You can also do that on this cell."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Solution to the first homework of Real life reinforcement learning\n",
      "import csv\n",
      "import math\n",
      "import numpy as np\n",
      "from sklearn import linear_model\n",
      "from sklearn import neighbors\n",
      "\n",
      "# First read in all the data from the file.\n",
      "with open('generated_episodes_3000.csv') as csv_file:\n",
      "    data = np.array(list(csv.reader(csv_file))[1:])\n",
      "\n",
      "# At this point all the data has been loaded into 'data'. I've ignored the first row because those are just labels that are \n",
      "# useless to us."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Uncomment the next statement if you want to see what a row of the data looks like.\n",
      "# data[0]\n",
      "# data[0].shape\n",
      "#print data[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing\n",
      "def get_known_states(data):\n",
      "    \"\"\"\n",
      "        Returns just the states that we know, i.e. states without the 'NA' in the data fields.\n",
      "    \"\"\"\n",
      "    event_length = 9 + 9 + 2\n",
      "    state_length = 9 + 2\n",
      "    num_states = 24\n",
      "    for episode in data:\n",
      "        # Start at the beginning and keep looking at a net length of len(s) + len(a) + len(r) + len(s') points\n",
      "        # Each time, we increment our start position by s+a+r = 11 points\n",
      "        curr_state = 0\n",
      "        while curr_state < num_states:\n",
      "            start_idx = curr_state * state_length\n",
      "            end_idx = start_idx + event_length\n",
      "            datum = episode[start_idx:end_idx]\n",
      "            try:\n",
      "                s = datum[:9].astype(np.float)\n",
      "                yield s\n",
      "            # There's a problem if a data field is 'NA' - Not entirely sure what do in that case so for now I'm just ignoring\n",
      "            # those data points\n",
      "            except ValueError:\n",
      "                pass    \n",
      "            curr_state += 1\n",
      "            \n",
      "def generate_sars(data):\n",
      "    \"\"\"\n",
      "        Function that returns the next (s, a, r, s') pair from the input data one by one every time you call it. Requires a \n",
      "        scaler to have been computed so that we can approximate the vaues for the 'NA' pairs in the data.\n",
      "    \"\"\"\n",
      "    # Compute the known states and then compute a 'scaler' which stores the means and variances that will be used for standardization.\n",
      "    known_states = [state for state in get_known_states(data)]\n",
      "    scaler = preprocessing.StandardScaler().fit(known_states)\n",
      "    event_length = 9 + 9 + 2\n",
      "    state_length = 9 + 2\n",
      "    num_states = 24\n",
      "    sars = []\n",
      "    for episode in data:\n",
      "        # Start at the beginning and keep looking at a net length of len(s) + len(a) + len(r) + len(s') points\n",
      "        # Each time, we increment our start position by s+a+r = 11 points\n",
      "        curr_state = 0\n",
      "        while curr_state < num_states:\n",
      "            start_idx = curr_state * state_length\n",
      "            end_idx = start_idx + event_length\n",
      "            datum = episode[start_idx:end_idx]\n",
      "            # If its normal data without 'NA', proceed as before except we 'scale' the values to mean-0 and variance-1\n",
      "            a = 1.0 if datum[9:10]=='true' else 0.0\n",
      "            r = np.asscalar(datum[10:11].astype(np.float))\n",
      "            try:\n",
      "                s = datum[:9].astype(np.float)\n",
      "                scaler.transform(s)\n",
      "                s_prime = datum[11:].astype(np.float)       \n",
      "                scaler.transform(s_prime)\n",
      "                sars.append([s, a, r, s_prime])\n",
      "            # IF there was a value error it means there was a 'NA' field somewhere. \n",
      "            except ValueError:\n",
      "                # ONLY S AND S' have these 'NA' fields (I've confirmed). Therefore we go through them and replace any\n",
      "                # fields that have 'NA' with the mean of the corresponding feature, and then apply the scaler.\n",
      "                s = np.array([elem if elem!='NA' else scaler.mean_[i].astype(np.float) for i, elem in enumerate(datum[:9])]).astype(np.float)\n",
      "                scaler.transform(s)\n",
      "                s_prime = np.array([elem if elem!='NA' else scaler.mean_[i].astype(np.float) for i, elem in enumerate(datum[:9])]).astype(np.float)\n",
      "                scaler.transform(s_prime).astype(np.float)\n",
      "                sars.append([s, a, r, s_prime])\n",
      "            curr_state += 1\n",
      "    return sars"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def FVI(fn, sars, gamma = 0.999, tol = 0.1):\n",
      "    \"\"\"\n",
      "        Does fixed value iteration using the input fn approximator on the input data (expected to be in SARS format)\n",
      "    \"\"\"\n",
      "    # From blackboard calculation\n",
      "    Br = max([r for s, a,r, s_prime in sars])\n",
      "    n_iters = math.log(((tol*(1-gamma**2))/Br) - gamma)\n",
      "    print n_iters\n",
      "    # Initialize the weights. Do one iteration to get things started\n",
      "    Xs = []\n",
      "    ys = []\n",
      "    for s, a, r, s_prime in sars:\n",
      "        y = r\n",
      "        Xs.append(np.append(s, a))\n",
      "        ys.append(y)\n",
      "    fn.fit(Xs, ys)\n",
      "    for i in range(iters):\n",
      "        Xs = []\n",
      "        ys = []\n",
      "        for s, a, r, s_prime in sars:\n",
      "            y = r + gamma * max(fn.predict(np.append(s_prime, 0.0)), fn.predict(np.append(s_prime, 1.0)))\n",
      "            Xs.append(np.append(s, a))\n",
      "            ys.append(y[0])\n",
      "        fn.fit(Xs, ys)\n",
      "    return fn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "With that the main loop of our FVI code is pretty simply defined as below:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# A key difference here is that we're just precomputing and storing all the s, a, r, s_prime pairs ahead of time. No generator\n",
      "# functions here.\n",
      "sars = generate_sars(data)\n",
      "\n",
      "# And now we'll have to do the following in a loop - Currently this is one iteration of proper FVI\n",
      "fn = linear_model.Lasso(alpha = 0.1)\n",
      "\n",
      "# Uncomment for K-NN\n",
      "#n_neighbors = 5\n",
      "#fn = neighbors.KNeighborsRegressor(n_neighbors, weights=\"distance\")\n",
      "\n",
      "FVI(fn, sars)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "math domain error",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-5-e8c97e58bc07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#fn = neighbors.KNeighborsRegressor(n_neighbors, weights=\"distance\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mFVI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-4-ffedb183b02a>\u001b[0m in \u001b[0;36mFVI\u001b[0;34m(fn, sars, gamma, tol)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# From blackboard calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mBr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_prime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mn_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mBr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Initialize the weights. Do one iteration to get things started\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: math domain error"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO:\n",
      "\n",
      "-> Figure out- How many iterations do we have to do that last cell for? When do we say we've converged\n",
      "\n",
      "-> OMP-TD for feature selection + possible feature set expansion\n",
      "\n",
      "-> LSPI (using LSTDQ already implemented)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_sarsa(data):\n",
      "    \"\"\"                                                                                                                                                                           \n",
      "        Function that returns the next (s, a, r, s', a') pair from the input data one by one every time you call it. Requires a                                                   \n",
      "        scaler to have been computed so that we can approximate the vaues for the 'NA' pairs in the data.                                                                         \n",
      "    \"\"\"\n",
      "    # Compute the known states and then compute a 'scaler' which stores the means and variances that will be used for standardization.                                            \n",
      "    known_states = [state for state in get_known_states(data)]\n",
      "    scaler = preprocessing.StandardScaler().fit(known_states)\n",
      "    event_length = 9 + 9 + 2 + 1\n",
      "    state_length = 9 + 2\n",
      "    num_states = 24\n",
      "    sarsa = []\n",
      "    for episode in data:\n",
      "        # Start at the beginning and keep looking at a net length of len(s) + len(a) + len(r) + len(s') points                                                                    \n",
      "        # Each time, we increment our start position by s+a+r = 11 points                                                                                                         \n",
      "        curr_state = 0\n",
      "        while curr_state < num_states:\n",
      "            start_idx = curr_state * state_length\n",
      "            end_idx = start_idx + event_length\n",
      "            datum = episode[start_idx:end_idx]\n",
      "            # If its normal data without 'NA', proceed as before except we 'scale' the values to mean-0 and variance-1                                                            \n",
      "            a = 1.0 if datum[9:10]=='true' else 0.0\n",
      "            r = np.asscalar(datum[10:11].astype(np.float))\n",
      "            try:\n",
      "                s = datum[:9].astype(np.float)\n",
      "                scaler.transform(s)\n",
      "                s_prime = datum[11:20].astype(np.float)\n",
      "                a_prime = 1.0 if datum[20:21] == 'true' else 0.0\n",
      "                scaler.transform(s_prime)\n",
      "                sarsa.append([s, a, r, s_prime, a_prime])\n",
      "            # IF there was a value error it means there was a 'NA' field somewhere.                                                                                               \n",
      "            except ValueError:\n",
      "                # ONLY S AND S' have these 'NA' fields (I've confirmed). Therefore we go through them and replace any                                                             \n",
      "                # fields that have 'NA' with the mean of the corresponding feature, and then apply the scaler.                                                                    \n",
      "                s = np.array([elem if elem!='NA' else scaler.mean_[i].astype(np.float) for i, elem in enumerate(datum[:9])]).astype(np.float)\n",
      "                scaler.transform(s)\n",
      "                s_prime = np.array([elem if elem!='NA' else scaler.mean_[i].astype(np.float) for i, elem in enumerate(datum[:9])]).astype(np.float)\n",
      "                scaler.transform(s_prime).astype(np.float)\n",
      "                sarsa.append([s, a, r, s_prime, a_prime])\n",
      "            curr_state += 1\n",
      "    return sarsa\n",
      "\n",
      "def LSTDQ(sars, current_pi, gamma = 0.9):\n",
      "\n",
      "    # at present, our basis is N^d - where d is 9 (features) + 1 (action)                                                                                                         \n",
      "    k = 10\n",
      "\n",
      "    # to avoid singularities, we start off A with a small delta along the diagonal                                                                                                \n",
      "    delta = 1e-03\n",
      "\n",
      "    # the \"A\" Matrix (kxk)                                                                                                                                                        \n",
      "    A = delta*np.eye(k)\n",
      "\n",
      "    # the b vector                                                                                                                                                                \n",
      "    b = np.zeros([k, 1], dtype=float)\n",
      "\n",
      "    # iterate through and build A and b                                                                                                                                           \n",
      "    for idx in range(0, len(sars)):\n",
      "\n",
      "        # In future implementations, we can have a different basis such as                                                                                                        \n",
      "        # RBF or a polynomial for our features                                                                                                                                    \n",
      "        # In the current implementation, we take the given features as the basis                                                                                                  \n",
      "        phi_s = np.reshape(np.append(sars[idx,0], sars[idx,1]), (k,1))\n",
      "        phi_s_prime = np.reshape(np.append(sars[idx,3], current_pi[idx,0]), (k,1))\n",
      "\n",
      "        # Update A - here, we add to A, a Rank 1 matrix formed by                                                                                                                 \n",
      "        # the vectors phi(s) and (phi(s) - gamma*phi(s'))                                                                                                                         \n",
      "        A = A + np.outer(phi_s, phi_s - gamma*phi_s_prime)\n",
      "\n",
      "        # update B - we add to B, the feature vector scaled by the reward                                                                                                         \n",
      "\n",
      "\n",
      "    # compute the weights for the policy pi - solve the system A*w_pi = b                                                                                                         \n",
      "    w_pi,_,_,_ = np.linalg.lstsq(A, b)\n",
      "\n",
      "    return w_pi\n",
      "\n",
      "\n",
      "# Policy Improvement                                                                                                                                                              \n",
      "def ImprovePolicy(s, w_pi):\n",
      "\n",
      "    # the new policy                                                                                                                                                              \n",
      "    policy = np.zeros((len(s),1))\n",
      "\n",
      "    # the value of the improved policy                                                                                                                                            \n",
      "    value = np.zeros((len(s),1))\n",
      "\n",
      "    # iterate through every state,                                                                                                                                                \n",
      "    for idx in range(0, len(s)):\n",
      "        # the state-action value for action 0.0                                                                                                                                   \n",
      "        q0 = np.dot(np.append(s[idx],0.0), w_pi)\n",
      "\n",
      "        # the state-action value for action 1.0                                                                                                                                   \n",
      "        q1 = np.dot(np.append(s[idx],1.0), w_pi)\n",
      "\n",
      "        # update the policy as argmax(action = {0.0, 1.0}) Q^                                                                                                                     \n",
      "        policy[idx] = 1.0 if q0 < q1 else 0.0\n",
      "\n",
      "        # update the value                                                                                                                                                        \n",
      "        value[idx] = max(q0, q1)\n",
      "\n",
      "        # to the next state                                                                                                                                                       \n",
      "        # idx = idx+1                                                                                                                                                             \n",
      "\n",
      "    return (policy, value)\n",
      "\n",
      "# Policy Evaluation at the given states                                                                                                                                           \n",
      "def EvaluatePolicy(s, w_pi):\n",
      "\n",
      "    # the value of the improved policy                                                                                                                                            \n",
      "    value = np.zeros((len(s),1))\n",
      "\n",
      "    # the new policy                                                                                                                                                              \n",
      "    policy = [False] * len(s)\n",
      "\n",
      "    # iterate through every state,                                                                                                                                                \n",
      "    for idx in range(0, len(s)):\n",
      "        # the state-action value for action 0.0                                                                                                                                   \n",
      "        q0 = np.dot(np.append(s[idx,0],0.0), w_pi)\n",
      "\n",
      "        # the state-action value for action 1.0                                                                                                                                   \n",
      "        q1 = np.dot(np.append(s[idx,0],1.0), w_pi)\n",
      "\n",
      "        # update the value                                                                                                                                                        \n",
      "        value[idx] = max(q0, q1)\n",
      "\n",
      "        # update the policy                                                                                                                                                       \n",
      "        policy[idx] = True if q0 < q1 else False\n",
      "\n",
      "    return (policy, value)\n",
      "\n",
      "def LSPI(sars, current_pi, gamma):\n",
      "    # the maximum number of iterations to run                                                                                                                                     \n",
      "    maxIter = 50\n",
      "\n",
      "    # the current loop counter                                                                                                                                                    \n",
      "    iter = 1\n",
      "\n",
      "    # epsilon tolerance to terminate the policy improvement                                                                                                                       \n",
      "    eps = 1e-02;\n",
      "\n",
      "    # the initial weight vector                                                                                                                                                   \n",
      "    w_pi = np.zeros((10,1))\n",
      "\n",
      "    # loop                                                                                                                                                                        \n",
      "    while iter < maxIter:\n",
      "\n",
      "        if 0 == iter%2:\n",
      "            print \"Now at policy iteration #{}\".format(iter)\n",
      "\n",
      "        # Estimate the State-Action VF Approximation using LSTDQ                                                                                                                  \n",
      "        new_w_pi = LSTDQ(sars, current_pi, gamma)\n",
      "\n",
      "        # improve the policy                                                                                                                                                      \n",
      "        new_pi, new_value = ImprovePolicy(sars[:,0], w_pi)\n",
      "\n",
      "        # termination condition                                                                                                                                                   \n",
      "        if np.linalg.norm(new_w_pi - w_pi) < eps:\n",
      "            print \"PI converged at iteration # {}\".format(iter)\n",
      "            break\n",
      "\n",
      "        # update current_pi                                                                                                                                                       \n",
      "        current_pi = new_pi\n",
      "\n",
      "        # update w_pi                                                                                                                                                             \n",
      "        w_pi = new_w_pi\n",
      "\n",
      "        # update current_value                                                                                                                                                    \n",
      "        current_value = new_value\n",
      "\n",
      "        # update iter                                                                                                                                                             \n",
      "        iter = iter + 1\n",
      "\n",
      "    return (current_pi, w_pi, current_value)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "def timeit(niters):\n",
      "    def decorator(f):\n",
      "        def wrapper(inp):\n",
      "            start = time.time()\n",
      "            for i in range(niters):\n",
      "                f(inp)\n",
      "                #pass\n",
      "            end = time.time()\n",
      "            print (end - start)/niters\n",
      "        return wrapper\n",
      "    return decorator\n",
      "\n",
      "niters = 10\n",
      "@timeit(niters)\n",
      "def a(inp):\n",
      "    counter = 0\n",
      "    for i in range(inp):\n",
      "        counter+=1\n",
      "\n",
      "a(1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000\n",
        "6.66069030762e-05"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def crossValidate(func):\n",
      "    \"\"\"\n",
      "        Run cross validation on a function and find the best value of gamma from that\n",
      "    \"\"\"\n",
      "    # the number of times to run the cross validation for a given gamma                                                                                                           \n",
      "    maxCVTimes  = 5\n",
      "\n",
      "    # the number of folds                                                                                                                                                         \n",
      "    numFolds  = 10\n",
      "\n",
      "    # number of test elements                                                                                               \n",
      "    numTestElements = len(sars)/numFolds\n",
      "\n",
      "    # number of training elements                                                                                                                                                 \n",
      "    numTrainElements = len(sars) - numTestElements\n",
      "\n",
      "    print \"Train Elements {}, Test Elements {}\".format(numTrainElements, numTestElements)\n",
      "\n",
      "    # the mean values of each of the policy                                                                                                                                       \n",
      "    mean_policy_values = np.zeros((len(gamma),1))\n",
      "\n",
      "    # iterate through all the elements of gamma                                                                                                                                   \n",
      "    for gIdx, g in enumerate(gamma):\n",
      "\n",
      "        print \"Cross validating for gamma: {0:.3f}\".format(g)\n",
      "\n",
      "        # the current loop counter                                                                                                                                                \n",
      "        cvTimes = 0\n",
      "\n",
      "        # iterate                                                                                                                                                                 \n",
      "        while cvTimes < maxCVTimes:\n",
      "\n",
      "            # get the training set rows                                                                                                                                           \n",
      "            trainRows = random.sample(range(0,len(sars)), numTrainElements)\n",
      "\n",
      "            # the test set rows                                                                                                                                                   \n",
      "            testRows = list(set(range(0,len(sars))) - set(trainRows))\n",
      "\n",
      "            #  the initial policy executed at s'                                                                                                                                  \n",
      "            current_pi = np.reshape(sarsa[:,4], (len(sars),1))\n",
      "\n",
      "            # LSPI                                                                                                                                                                \n",
      "            _, w_pi,_ = LSPI(sars[trainRows,:], current_pi, g)\n",
      "\n",
      "            # evaluate the policy at sars[testRows,:]                                                                                                                             \n",
      "            _,values = EvaluatePolicy(sars[testRows,0:1], w_pi)\n",
      "\n",
      "            # update the mean_policy_values for the current gamma                                                                                                                 \n",
      "            mean_policy_values[gIdx] = mean_policy_values[gIdx] + np.mean(values)\n",
      "\n",
      "            # tick over the counter                                                                                                                                               \n",
      "            cvTimes = cvTimes + 1\n",
      "\n",
      "        # average over all the cross-validation times                                                                                                                             \n",
      "        mean_policy_values[gIdx,0] = mean_policy_values[gIdx,0]/float(maxCVTimes)\n",
      "\n",
      "        # console log                                                                                                                                                             \n",
      "        print \"Mean policy value for test set: {0:.2f}\".format(mean_policy_values[gIdx,0])\n",
      "\n",
      "    # write the gamma values to the csv file                                                                                                                                      \n",
      "    with open(\"LSPI_gamma_CV.csv\", \"w\") as out_file:\n",
      "        out_file.write(\"# Gamma, Mean Policy Value\\n\")\n",
      "        for i in range(len(gamma)):\n",
      "            out_string = \"{0:.5f},{1:.5f}\\n\".format(gamma[i],mean_policy_values[i,0])\n",
      "            out_file.write(out_string)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([[[  60.86    2.      3.      6.     29.    141.     15.      5.      0.  ],\n",
        "        1.0, -0.68,\n",
        "        [  60.86    2.      3.      6.     29.    141.     15.      5.      0.  ]],\n",
        "       [[  49.    6.    7.   10.   59.  175.   20.    2.    2.], 1.0,\n",
        "        -0.68, [  49.    6.    7.   10.   60.  175.   20.    3.    0.]],\n",
        "       [[  87.    2.    7.   16.   81.  130.    9.    1.    0.], 1.0,\n",
        "        -0.68, [  87.    2.    7.   16.   82.  130.    9.    2.    0.]],\n",
        "       [[ 64.   6.   4.   8.  45.  86.  20.   1.   1.], 1.0, -0.68,\n",
        "        [ 64.   6.   4.   8.  46.  86.  20.   2.   0.]],\n",
        "       [[ 49.     3.96   9.     9.    36.    89.     5.     3.     0.  ],\n",
        "        0.0, 0.0,\n",
        "        [ 49.     3.96   9.     9.    36.    89.     5.     3.     0.  ]],\n",
        "       [[ 40.    5.    8.    0.    9.    0.   13.    5.5   0.6], 1.0,\n",
        "        14.32, [ 40.    5.    8.    0.    9.    0.   13.    5.5   0.6]],\n",
        "       [[ 60.8    3.96   3.     4.    19.    52.     6.     0.     0.  ],\n",
        "        0.0, 0.0,\n",
        "        [ 60.8    3.96   3.     4.    19.    52.     6.     0.     0.  ]],\n",
        "       [[ 30.   4.   8.  10.  48.  44.   4.  13.   0.], 0.0, 0.0,\n",
        "        [ 30.   4.   8.  10.  48.  44.   4.  14.   1.]],\n",
        "       [[ 43.   7.  10.   6.  28.  35.   5.   3.   2.], 1.0, -0.68,\n",
        "        [ 43.   7.  10.   6.  29.  35.   5.   4.   0.]],\n",
        "       [[  71.    2.    2.    7.   38.  115.   20.    8.    0.], 0.0, 0.0,\n",
        "        [  71.    2.    2.    7.   38.  115.   20.    9.    1.]]], dtype=object)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}